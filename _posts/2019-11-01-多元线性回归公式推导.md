---
layout:     post       
title:      多元线性回归公式推导
# subtitle:   Hello World, Hello Blog 
date:       2019-11-01
author:     BY CSW996
# header-img: img/post-bg-2015.jpg
catalog: true
tags:
    - 西瓜书
---

==推导思路==

损失函数-->凸函数-->一阶偏导为**零向量**
$$
\begin{align}
f(x_i) &=w^Tx_i+b\\
&=(w_1,w_2,\cdots,w_d)
\left(
\begin{matrix}
x_{i1}\\
x_{i2}\\
\vdots\\
x_{id}\\
\end{matrix}
\right)+b\\
&=w_1x_{i1}+w_2x_{i2}+\cdots+w_dx_{id}+b\\
&=w_1x_{i1}+w_2x_{i2}+\cdots+w_dx_{id}+w_{d+1}\cdot 1\\
&=(w_1,w_2,\cdots,w_d,w_{d+1})
\left(
\begin{matrix}
x_{i1}\\
x_{i2}\\
\vdots\\
x_{id}\\
1
\end{matrix}
\right)\\
\Rightarrow f(\hat{x_i})=\hat{w}^T\hat{x_i} 
\end{align}
$$

### 损失函数

$$
\begin{align}
E(\hat{w}) &=\sum_{i=1}^m(y_i-f(\hat{x_i}))^2\\
&=\sum_{i=1}^m(y_i-\hat{w}^T\hat{x_i} )^2
\end{align}
$$

令
$$
X=
\left(
\begin{matrix}
x_{11} &x_{12} &\cdots &x_{1d} &1\\
x_{21} &x_{22} &\cdots &x_{2d} &1\\
\vdots &\vdots &\ddots &\vdots &\vdots\\
x_{m1} &x_{m2} &\cdots &x_{md} &1\\
\end{matrix}
\right)
=\left(
\begin{matrix}
x_1^T &1\\
x_2^T &1\\
\vdots &\vdots\\
x_m^T &1\\
\end{matrix}
\right)
=\left(
\begin{matrix}
\hat{x_1^T}\\
\hat{x_2^T}\\
\vdots \\
\hat{x_m^T}\\
\end{matrix}
\right)
\\
y=(y_1,y_2,\cdots,y_m)^T
$$
所以，
$$
\begin{align}
E(\hat{w}) &=(y_1-\hat{w}^T\hat{x_1})^2+(y_2-\hat{w}^T\hat{x_2})^2+\cdots+(y_m-\hat{w}^T\hat{x_m})^2\\
&=
\left(
\begin{matrix}
y_1-\hat{w}^T\hat{x_1} &
y_2-\hat{w}^T\hat{x_2} &
\cdots &
y_m-\hat{w}^T\hat{x_m}
\end{matrix}
\right)\cdot
\left(
\begin{matrix}
y_1-\hat{w}^T\hat{x_1} \\
y_2-\hat{w}^T\hat{x_2} \\
\vdots \\
y_m-\hat{w}^T\hat{x_m}
\end{matrix}
\right)
\end{align}
$$
其中,
$$
\begin{align}

\left(
\begin{matrix}
y_1-\hat{w}^T\hat{x_1} \\
y_2-\hat{w}^T\hat{x_2} \\
\vdots \\
y_m-\hat{w}^T\hat{x_m}
\end{matrix}
\right)&=

\left(
\begin{matrix}
y_1\\ y_2\\ \vdots \\ y_m
\end{matrix}
\right)_{d\times1}
-
\left(
\begin{matrix}
\hat{w}^T\hat{x_1} \\
\hat{w}^T\hat{x_2} \\
\vdots \\
\hat{w}^T\hat{x_m}
\end{matrix}
\right)_{d\times1}
\end{align}
$$
因为，$\hat{w}^T\cdot\hat{x_i}$是一个横向量$\times$一个列向量，所以结果是一个标量，也就是$\hat{w}^T\cdot\hat{x_i}=(\hat{w}^T\cdot\hat{x_i})^T=\hat{x_i}^T\hat{w}$

所以就有，
$$
\begin{align}

\left(
\begin{matrix}
y_1-\hat{w}^T\hat{x_1} \\
y_2-\hat{w}^T\hat{x_2} \\
\vdots \\
y_m-\hat{w}^T\hat{x_m}
\end{matrix}
\right)
&=\left(\begin{array}{c}{y_{1}} \\ {y_{2}} \\ {\vdots} \\ {y_{d}}\end{array}\right)-\left(\begin{array}{c}{\hat{\boldsymbol{x}}_{1}^{T} \hat{\boldsymbol{w}}} \\ {\hat{\boldsymbol{x}}_{2}^{T} \hat{\boldsymbol{w}}} \\ {\vdots} \\ {\hat{\boldsymbol{x}}_{d}^{T} \hat{\boldsymbol{w}}}\end{array}\right)\\
&=\left(\begin{array}{c}{y_{1}} \\ {y_{2}} \\ {\vdots} \\ {y_{d}}\end{array}\right)-\left(
\begin{array}{c}
({\hat{\boldsymbol{x}}_{1}^{T}})_{1\times (d+1)} \\ 
{\hat{\boldsymbol{x}}_{2}^{T}} \\ 
{\vdots} \\ 
{\hat{\boldsymbol{x}}_{m}^{T}}
\end{array}\right)_{m\times (d+1)}
\cdot \hat{\boldsymbol{w}}_{(d+1)\times1}\\
&=y-X\cdot \hat{w}
\end{align}
$$

$$
\Rightarrow 
\begin{align}
E_{\hat{w}}&=\left(\begin{array}{ccccc}{y_{1}-\hat{w}^{T} \hat{x}_{1}} & {y_{2}-\hat{w}^{T} \hat{x}_{2}} & {\cdots} & {y_{d}-\hat{w}^{T} \hat{x}_{d}}\end{array}\right)\left(\begin{array}{c}{y_{1}-\hat{w}^{T} \hat{x}_{1}} \\ {y_{2}-\hat{w}^{T} \hat{x}_{2}} \\ {\vdots} \\ {y_{d}-\hat{w}^{T} \hat{x}_{d}}\end{array}\right)\\
&=(y-X\hat{w})^T\cdot(y-X\hat{w})\tag{3.9 argmin}
\end{align}
$$

### 证明凸函数

#### ==多元实值函数证明凹凸性问题==

- **凸集：**设集合$D \in R^{n}$，如果对任意的$x, y \in D$与任意的$a \in[0,1]$，有$a \boldsymbol{x}+(1-a) \boldsymbol{y} \in D$，则称集合$D$是凸集。

- **梯度：**设$n$元函数$f(\boldsymbol{x})$对自变量$\boldsymbol{x}=\left(x_{1}, x_{2}, \ldots, x_{n}\right)^{T}$各分量$x_{i}$的偏导数$\frac{\partial f(\boldsymbol{x})}{\partial x_{i}} \quad(i=1,2, \ldots, n)$都存在，则称函数$f(\boldsymbol{x})$在$\boldsymbol{x}$处可导，并称向量
  $$
  \nabla f(\boldsymbol{x})=\left(\begin{array}{c}{\frac{\partial f(\boldsymbol{x})}{\partial x_{1}}} \\ {\frac{\partial f(\boldsymbol{x})}{\partial x_{2}}} \\ {\vdots} \\ {\frac{\partial f(\boldsymbol{x})}{\partial x_{n}}}\end{array}\right)
  $$
  为函数$f(\boldsymbol{x})$在$x$处的一阶导数或梯度，记为$\nabla f(\boldsymbol{x})$（列向量）

- **Hessian海塞矩阵定义：**设n元函数$f(x)$对自变量$x$的各分量$\boldsymbol{x}=\left(x_{1}, x_{2}, \ldots, x_{n}\right)^{T}$的二阶偏导数$\frac{\partial^{2} f(\boldsymbol{x})}{\partial x_{i} \partial x_{j}} \quad(i=1,2, \ldots, n ; j=1,2, \ldots, n)$都存在，则称函数$f(x)$在$x$处二阶可导，并称矩阵
  $$
  \nabla^{2} f(\boldsymbol{x})=\left[\begin{array}{cccc}{\frac{\partial^{2} f(\boldsymbol{x})}{\partial x_{1}^{2}}} & {\frac{\partial^{2} f(\boldsymbol{x})}{\partial x_{1} \partial x_{2}}} & {\cdots} & {\frac{\partial^{2} f(\boldsymbol{x})}{\partial x_{1} \partial x_{n}}} \\ {\frac{\partial^{2} f(\boldsymbol{x})}{\partial x_{2} \partial x_{1}}} & {\frac{\partial^{2} f(\boldsymbol{x})}{\partial x_{2}^{2}}} & {\cdots} & {\frac{\partial^{2} f(\boldsymbol{x})}{\partial x_{2} \partial x_{n}}} \\ {\vdots} & {\vdots} & {\ddots} & {\vdots} \\ {\frac{\partial^{2} f(\boldsymbol{x})}{\partial x_{n} \partial x_{1}}} & {\frac{\partial^{2} f(\boldsymbol{x})}{\partial x_{n} \partial x_{2}}} & {\cdots} & {\frac{\partial^{2} f(\boldsymbol{x})}{\partial x_{n}^{2}}}\end{array}\right]
  $$
  为$f(x)$在$x$处的二阶导数或海塞矩阵，记为$\nabla^{2} f(\boldsymbol{x})$，若$f(x)$对$x$各变元的所有二阶偏导数都连续，则$\frac{\partial^{2} f(\boldsymbol{x})}{\partial x_{i} \partial x_{j}}=\frac{\partial^{2} f(\boldsymbol{x})}{\partial x_{j} \partial x_{i}}$此时$\nabla^{2} f(\boldsymbol{x})$为对称矩阵。

- 判断凹凸型的定理：

  ![image-20191101142033611](/Users/jinfei/Library/Application Support/typora-user-images/image-20191101142033611.png)

#### 求解权重$\hat{w}$的公式推导

证明损失函数$E_\hat{w}$是关于$\hat{w}$的凸函数：
$$
\begin{align}
\frac{\partial E_{\hat{\boldsymbol{w}}}}{\partial \hat{\boldsymbol{w}}}&=\frac{\partial}{\partial \hat{\boldsymbol{w}}}\left[(\boldsymbol{y}-\mathbf{X} \hat{\boldsymbol{w}})^{T}(\boldsymbol{y}-\mathbf{X} \hat{\boldsymbol{w}})\right]\\
&=\frac{\partial}{\partial \hat{\boldsymbol{w}}}\left[\left(\boldsymbol{y}^{T}-\hat{\boldsymbol{w}}^{T} \mathbf{X}^{T}\right)(\boldsymbol{y}-\mathbf{X} \hat{\boldsymbol{w}})\right]\\
&=\frac{\partial}{\partial \hat{\boldsymbol{w}}}\left[\boldsymbol{y}^{T} \boldsymbol{y}-\boldsymbol{y}^{T} \mathbf{X} \hat{\boldsymbol{w}}-\hat{\boldsymbol{w}}^{T} \mathbf{X}^{T} \boldsymbol{y}+\hat{\boldsymbol{w}}^{T} \mathbf{X}^{T} \mathbf{X} \hat{\boldsymbol{w}}\right]\\
&=\frac{\partial}{\partial \hat{\boldsymbol{w}}}\left[-\boldsymbol{y}^{T} \mathbf{X} \hat{\boldsymbol{w}}-\hat{\boldsymbol{w}}^{T} \mathbf{X}^{T} \boldsymbol{y}+\hat{\boldsymbol{w}}^{T} \mathbf{X}^{T} \mathbf{X} \hat{\boldsymbol{w}}\right]
\end{align}
$$
==矩阵微分公式==
$$
\frac{\partial y}{\partial \boldsymbol{x}}=\left(\begin{array}{c}{\frac{\partial y}{\partial x_{1}}} \\ {\frac{\partial y}{\partial x_{2}}} \\ {\vdots} \\ {\frac{\partial y}{\partial x_{n}}}\end{array}\right)
$$

$$
\frac{\partial y}{\partial \boldsymbol{x}}=\left(\begin{array}{cccc}{\frac{\partial y}{\partial x_{1}}} & {\frac{\partial y}{\partial x_{2}}} & {\cdots} & {\frac{\partial y}{\partial x_{n}}}\end{array}\right)
$$

可以推得一些结论：
$$
\Rightarrow \frac{\partial \boldsymbol{x}^{T} \boldsymbol{a}}{\partial \boldsymbol{x}}=
\frac{\partial \boldsymbol{a}^{T} \boldsymbol{x}}{\partial \boldsymbol{x}}=
\left(\begin{array}{c}{\frac{\partial\left(a_{1} x_{1}+a_{2} x_{2}+\ldots+a_{n} x_{n}\right)}{\partial x_{1}}} \\ {\frac{\partial\left(a_{1} x_{1}+a_{2} x_{2}+\ldots+a_{n} x_{n}\right)}{\partial x_{2}}} \\ {\vdots} \\ {\frac{\partial\left(a_{1} x_{1}+a_{2} x_{2}+\ldots+a_{n} x_{n}\right)}{\partial x_{n}}}\end{array}\right)
=\left(\begin{array}{c}{a_{1}} \\ {a_{2}} \\ {\vdots} \\ {a_{n}}\end{array}\right)
=\boldsymbol{a}\tag{a.1}
$$
同理，推得：$\frac{\partial \boldsymbol{x}^{T} \mathbf{B} \boldsymbol{x}}{\partial \boldsymbol{x}}=\left(\mathbf{B}+\mathbf{B}^{T}\right) \boldsymbol{x}\tag{a.2}$

回到上面的凸函数推导，
$$
\begin{align}
\frac{\partial E_{\hat{\boldsymbol{w}}}}{\partial \hat{\boldsymbol{w}}}&=\frac{\partial}{\partial \hat{\boldsymbol{w}}}\left[-\boldsymbol{y}^{T} \mathbf{X} \hat{\boldsymbol{w}}-\hat{\boldsymbol{w}}^{T} \mathbf{X}^{T} \boldsymbol{y}+\hat{\boldsymbol{w}}^{T} \mathbf{X}^{T} \mathbf{X} \hat{\boldsymbol{w}}\right]\\
&=-\frac{\partial \boldsymbol{y}^{T} \mathbf{X} \hat{\boldsymbol{w}}}{\partial \hat{\boldsymbol{w}}}-\frac{\partial \hat{\boldsymbol{w}}^{T} \mathbf{X}^{T} \boldsymbol{y}}{\partial \hat{\boldsymbol{w}}}+\frac{\partial \hat{\boldsymbol{w}}^{T} \mathbf{X}^{T} \mathbf{X} \hat{\boldsymbol{w}}}{\partial \hat{\boldsymbol{w}}}\\
&=-\mathbf{X}^{T} \boldsymbol{y}-\mathbf{X}^{T} \boldsymbol{y}+\left(\mathbf{X}^{T} \mathbf{X}+\mathbf{X}^{T} \mathbf{X}\right) \hat{w}\tag{由a.1/a.2推得}\\
&=2 \mathbf{X}^{T}(\mathbf{X} \hat{w}-\boldsymbol{y})\tag{3.10}
\end{align}
$$
得到一阶偏导数后求二阶偏导，
$$
\begin{align}
\frac{\partial^{2} E_{\hat{w}}}{\partial \hat{w} \partial \hat{w}^{T}}&=\frac{\partial}{\partial \hat{w}}\left(\frac{\partial E_{\hat{w}}}{\partial \hat{w}}\right)\\
&=\frac{\partial}{\partial \hat{w}}[2X^T(X\hat{w}-y)]\\
&=\frac{\partial}{\partial \hat{w}}[2X^TX\hat{w}-2X^Ty]\\
&=(2X^TX)^T\\
&=2X^TX\tag{是海塞矩阵}
\end{align}
$$
假设$X^TX$是正定矩阵（西瓜书里提前假设了），==所以损失函数$E_\hat{w}$是关于$\hat{w}$的凸函数==

### 令一阶导数等于0解出$\hat{w}$

$$
\begin{align}
\frac{\partial E_{\hat{\boldsymbol{w}}}}{\partial \hat{\boldsymbol{w}}}&=2 \mathbf{X}^{T}(\mathbf{X} \hat{w}-\boldsymbol{y})\\
\Rightarrow 2X^TX\hat{w}&=2X^Ty\\
\Rightarrow (X^TX)^{-1}X^TX\hat{w}&=(X^TX)^{-1}X^Ty\\
\hat{w}&=(X^TX)^{-1}X^Ty\tag{3.11}=0
\end{align}
$$

